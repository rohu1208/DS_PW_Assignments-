{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11571196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7629f029",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bbfd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Eigenvalues and Eigenvectors\n",
    "# For a square matrix A, an eigenvalue λ and its corresponding eigenvector v satisfy A v = λ v.\n",
    "# This means v only scales by λ when transformed by A.\n",
    "# Example: For matrix A = [[2, 1], [1, 2]], eigenvalues are 3 and 1, with corresponding eigenvectors [1, 1] and [-1, 1].\n",
    "\n",
    "# Q2. Eigen Decomposition\n",
    "# It is the factorization of a matrix A into A = V Λ V^-1, where V is a matrix of eigenvectors and Λ is a diagonal matrix of eigenvalues.\n",
    "# It simplifies matrix operations, solving systems, and analyzing matrix properties.\n",
    "\n",
    "# Q3. Diagonalizability Conditions\n",
    "# A matrix A is diagonalizable if it has n linearly independent eigenvectors (for an n x n matrix).\n",
    "# Proof: If A has n independent eigenvectors, form matrix V from these vectors and diagonal matrix Λ with eigenvalues.\n",
    "# Then A = V Λ V^-1 holds true.\n",
    "\n",
    "# Q4. Spectral Theorem\n",
    "# It states that a symmetric matrix A can be diagonalized by an orthogonal matrix.\n",
    "# This implies symmetric matrices are always diagonalizable, and their eigenvalues are real.\n",
    "# Example: For A = [[2, 1], [1, 2]], eigenvalues are real, and it is diagonalizable.\n",
    "\n",
    "# Q5. Finding Eigenvalues\n",
    "# Solve the characteristic equation det(A - λ I) = 0.\n",
    "# Eigenvalues represent the scaling factor by which eigenvectors are stretched or compressed under the matrix transformation.\n",
    "\n",
    "# Q6. Eigenvectors\n",
    "# Non-zero vectors v such that A v = λ v.\n",
    "# They are directions in which the transformation A scales vectors by the eigenvalue λ.\n",
    "\n",
    "# Q7. Geometric Interpretation\n",
    "# Eigenvectors represent directions in the vector space that remain invariant under a linear transformation.\n",
    "# Eigenvalues describe the factor by which these directions are stretched or compressed.\n",
    "\n",
    "# Q8. Real-World Applications\n",
    "# - Principal Component Analysis (PCA): Reduces dimensionality by identifying principal components.\n",
    "# - Google’s PageRank: Uses eigenvectors to rank web pages.\n",
    "# - Vibration Analysis: Eigenvalues describe natural frequencies of structures.\n",
    "\n",
    "# Q9. Multiple Eigenvectors/Eigenvalues\n",
    "# A matrix can have multiple eigenvectors corresponding to the same eigenvalue (especially if the eigenvalue is repeated).\n",
    "\n",
    "# Q10. Applications in Data Analysis/ML\n",
    "# - PCA: Dimensionality reduction and feature extraction.\n",
    "# - Spectral Clustering: Data clustering based on eigenvectors of similarity matrices.\n",
    "# - Latent Semantic Analysis: Dimensionality reduction in text processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b2aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
